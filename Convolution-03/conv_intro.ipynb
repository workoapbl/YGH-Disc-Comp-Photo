{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83137687",
   "metadata": {},
   "source": [
    "# Convolution Tutorial\n",
    "\n",
    "In this notebook, we'll walk through the basics of convolution in images and walk you through implementing your own convolution function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03114b45",
   "metadata": {},
   "source": [
    "### What is convolution?\n",
    "\n",
    "<img src=\"lesson_files/same_padding_no_strides.gif\" alt=\"Convolution Same Padding Animation\" width=\"300\"/>\n",
    "\n",
    "Convolution is a way to edit an image by moving a tiny filter across it and changing each pixel based on the pixels around it. Different filters can make the image look blurry, sharper, show outlines/edges, create a 3D “stamped” look, add motion streaks, or add a soft glow around bright areas.\n",
    "\n",
    "#### Key Terminology:\n",
    "* <b>Kernel:</b> This is the filter that we apply to the image\n",
    "* <b>Stride:</b> How far the kernel moves at each step (moving more than 1 step will make the output smaller).\n",
    "* <b>Padding:</b> Adding extra pixels around the edge so the effect can be applied to edge pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25074e6c",
   "metadata": {},
   "source": [
    "### Correlation vs. Convolution\n",
    "\n",
    "Correlation slides the filter over the image exactly as written to combine nearby pixels. Convolution does the same sliding, but it flips the filter first (left-right and up-down) before applying it.\n",
    "\n",
    "<b>In this class, we will treat correlation as convolution (which is done commonly in image editing applications).</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0449c4c8",
   "metadata": {},
   "source": [
    "### Exercises before we start:\n",
    "\n",
    "When we apply a kernel to an image, we have a **kernel** and our **input image**. \n",
    "\n",
    "<img src=\"lesson_files/conv_im.png\" alt=\"matrix im\" width=\"500\"/>\n",
    "\n",
    "At each point, we think of our kernel as a mask. We multiply the value in the kernel and the value in the image that lines up with the kernel. We sum this for every pixel covered by the kernel, and this is our new value.\n",
    "\n",
    "\n",
    "<img src=\"lesson_files/combo_ex.gif\" alt=\"Convolution Same Padding Animation\" width=\"600\"/>\n",
    "\n",
    "In the next exercise, we'll implement this on a small scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f709fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1\n",
    "# We will give you a kernel in the variable K and an array representing a 'patch' of an image.\n",
    "# Your task is to apply the convolution with the kernel K onto the image patch using code.\n",
    "\n",
    "import numpy as np\n",
    "K = np.array([[1, 0, -1],\n",
    "              [3, 0, -3],\n",
    "              [1, 0, -1]])\n",
    "\n",
    "image_patch = np.array([[10, 60, 10],\n",
    "                        [60, 235, 60],\n",
    "                        [10, 60, 10]])\n",
    "\n",
    "# fill in this function:\n",
    "def conv_image_patch(K, image_patch):\n",
    "    \"\"\"\n",
    "    Apply a convolution with the kernel K onto the image patch.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return\n",
    "\n",
    "print(conv_image_patch(K, image_patch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5bc4fe",
   "metadata": {},
   "source": [
    "### Next step:\n",
    "\n",
    "What you just coded applies the kernel to one patch. But now, let's try applying the kernel to the entire image. One issue you might run into is the problem of how to handle the borders of the image since the kernel will 'run over' the edges of the image. \n",
    "\n",
    "For now, **don't** worry about edge behavior. Only apply the kernel to pixels where the kernel will not go out of bounds. **This will result in a slightly smaller image.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3edb041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: More on Convolution\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('images/llama_bw.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "def conv_image(img, kernel):\n",
    "    \"\"\"\n",
    "    Apply a convolution with the kernel K onto the image patch.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return \n",
    "\n",
    "def blur_image(img):\n",
    "    kernel = np.ones((10,10), dtype=np.float32) / 100\n",
    "    return conv_image(img, kernel)\n",
    "\n",
    "blurred = blur_image(img)\n",
    "blurred = np.clip(blurred, 0, 255).astype(np.uint8)\n",
    "# Show the result\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"With Kernel\")\n",
    "plt.imshow(blurred, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4380b697",
   "metadata": {},
   "source": [
    "### Handling Edges in Convolution\n",
    "\n",
    "We are going to look at two ways of handling edges in convolution. \n",
    "\n",
    "1. **Method 1**: Treating all 'outside' pixels as black. This means that when you have a kernel that goes outside of the image, the pixels that the kernel tries to access that are not in the image are treated as black pixels (value 0).\n",
    "2. **Method 2**: Extending pixels off the image. We can think of this as the edges of the image extending infinitely off the image as shown in the image below.\n",
    "\n",
    "<img src=\"lesson_files/extend_graphic.svg\" alt=\"Extending behavior\" width=\"400\"/>\n",
    "\n",
    "**Your next task:** Copy your code from Task 2 (llama convolution) and code the two methods mentioned. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a12b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "def conv_image(img, kernel, edge_behavior='black'):\n",
    "    \"\"\"\n",
    "    Apply a convolution with the kernel K onto the image patch.\n",
    "    Handles two edge cases: outside pixels are black, and outside pixels are extended.\n",
    "    \"\"\"\n",
    "    if edge_behavior not in ['black', 'extend']:\n",
    "        raise ValueError(\"Invalid edge behavior. Must be 'black' or 'extend'.\")\n",
    "    # YOUR CODE HERE\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd00a3",
   "metadata": {},
   "source": [
    "### More fun with kernels\n",
    "\n",
    "Using your `conv_image` function from above, we're going to learn how to **sharpen** an image. To sharpen an image, we **subtract** away a blurred version of the image. Let $I$ equal our original image. Let $B$ be our blurred image. We achieve our sharpened image $S$ using the following equation:\n",
    "\n",
    "$$\n",
    "S = 2I - B\n",
    "$$\n",
    "\n",
    "This means that we **double** our original image and subtract our blurred image once. Try this below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60953cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Sharpening\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load one of the following images to work with\n",
    "img = cv2.imread('images/llama_bw.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "# img = cv2.imread('images/owl_bw.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "# img = cv2.imread('images/lizard_bw.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "# img = cv2.imread('images/cow_bw.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "def sharpen_image(img):\n",
    "    \"\"\"\n",
    "    Sharpen an image using the formula S = 2I - B, where I is the original image and B is the blurred image.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return \n",
    "\n",
    "# display the sharpened image\n",
    "plt.imshow(sharpen_image(img), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c96aa9d",
   "metadata": {},
   "source": [
    "### Challenge: Convolution on Colored Images\n",
    "\n",
    "To perform convolution on a color image, you need to apply the convolution operation separately on each color channel (for example, Red, Green, and Blue channels in an RGB image). \n",
    "\n",
    "This means that you would:\n",
    " 1. Split the color image into its individual channels.\n",
    " 2. Apply your convolution function to each channel independently.\n",
    " 3. Merge the resulting convolved channels back together to form the final output image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f2222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge Code Here\n",
    "\n",
    "def conv_image(img, kernel, edge_behavior='black'):\n",
    "    \"\"\"\n",
    "    Apply a convolution with the kernel K onto the image patch.\n",
    "    Handles two edge cases: outside pixels are black, and outside pixels are extended.\n",
    "    Update: Now supports both grayscale (2D) and color (3D) images.\n",
    "    \"\"\"\n",
    "    if edge_behavior not in ['black', 'extend']:\n",
    "        raise ValueError(\"Invalid edge behavior. Must be 'black' or 'extend'.\")\n",
    "    \n",
    "    def conv_image_channel(img, kernel, edge_behavior='black'):\n",
    "        \"\"\"\n",
    "        Apply a convolution with the kernel K onto the image patch.\n",
    "        Handles two edge cases: outside pixels are black, and outside pixels are extended.\n",
    "        \"\"\"\n",
    "        if edge_behavior not in ['black', 'extend']:\n",
    "            raise ValueError(\"Invalid edge behavior. Must be 'black' or 'extend'.\")\n",
    "        # YOUR CODE HERE\n",
    "        return\n",
    "\n",
    "bw_llama = cv2.imread('images/llama_bw.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "color_llama = cv2.imread('images/llama.jpg')\n",
    "\n",
    "blur_kernel = np.ones((10,10)) / 100\n",
    "bw_blurred = conv_image(bw_llama, blur_kernel)\n",
    "color_blurred = conv_image(color_llama, blur_kernel)\n",
    "\n",
    "bw_blurred = np.clip(bw_blurred, 0, 255).astype(np.uint8)\n",
    "color_blurred = np.clip(color_blurred, 0, 255).astype(np.uint8)\n",
    "# display the blurred images\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Grayscale Blurred\")\n",
    "plt.imshow(bw_blurred, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Color Blurred\")\n",
    "plt.imshow(cv2.cvtColor(color_blurred, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "photo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
